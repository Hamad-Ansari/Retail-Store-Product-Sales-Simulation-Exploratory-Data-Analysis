# ğŸª Retail Store Product Sales Simulation: Comprehensive EDA ğŸ“Šâœ¨

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Pandas](https://img.shields.io/badge/Pandas-orange.svg)
![Seaborn](https://img.shields.io/badge/Seaborn-lightgrey.svg)
![Matplotlib](https://img.shields.io/badge/Matplotlib-red.svg)
![Jupyter](https://img.shields.io/badge/Jupyter-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg) <!-- You can change this to your desired license -->

---

## ğŸ“ Table of Contents

1.  [About the Project](#-about-the-project)
2.  [Dataset Overview](#-dataset-overview)
3.  [Objectives](#-objectives)
4.  [Methodology](#-methodology)
5.  [Key Findings & Insights](#-key-findings--insights)
6.  [Highlighted Visualizations](#-highlighted-visualizations)
7.  [Key Business Questions Answered](#-key-business-questions-answered)
8.  [Technical Stack](#-technical-stack)
9.  [How to Use/Run](#-how-to-userun)
10. [Future Work](#-future-work)
11. [Author & Contact](#-author--contact)
12. [License](#-license)

---

## ğŸš€ About the Project

This repository hosts a comprehensive Exploratory Data Analysis (EDA) performed on the `Retail Store Product Sales Simulation Dataset`. The goal was to uncover patterns, relationships, and actionable insights within a synthetic yet realistic retail sales environment. By dissecting various factors like pricing, promotions, customer sentiment, and competition, this analysis lays the groundwork for advanced modeling and strategic decision-making in retail analytics.

The accompanying Jupyter Notebook (`retail_sales_eda.ipynb`) meticulously walks through each step of the EDA process, from initial data quality checks to advanced visualizations and business-driven question answering.

---

## ğŸ“š Dataset Overview

The **Retail Store Product Sales Simulation Dataset** is designed for experimentation, modeling, and learning in retail analytics. It simulates daily product-level data across a fictional retail chain, where each feature is nonlinearly dependent on others to mimic realistic sales dynamics.

-   **Rows:** 15,000 (daily snapshots of product performance)
-   **Columns:** 11 numeric features

**Features:**
-   `price`: Product base price ğŸ’µ
-   `discount`: Discount applied to the product ğŸ¯
-   `promotion_intensity`: Strength of ongoing promotional campaigns ğŸ“¢
-   `footfall`: Number of customers visiting the store ğŸ‘¥
-   `ad_spend`: Advertising spend for the product/store ğŸ“º
-   `competitor_price`: Average competitor pricing ğŸ·ï¸
-   `stock_level`: Available stock in the store ğŸ“¦
-   `weather_index`: Simplified indicator of weather conditions affecting sales â˜€ï¸ğŸŒ§ï¸
-   `customer_sentiment`: Estimated customer satisfaction ğŸ˜ŠğŸ˜ğŸ˜
-   `return_rate`: Proportion of products returned by customers ğŸ”„

**Key Characteristics:**
-   **Synthetic but Realistic:** Features are nonlinearly interdependent, introducing correlations, seasonality, and complex interactions.
-   **Clean:** No real-world identifiers, perfectly clean with no missing values.

---

## ğŸ¯ Objectives

The primary objectives of this EDA were to:

1.  **Understand Data Structure & Quality:** Assess the dataset's cleanliness, types, and overall integrity.
2.  **Explore Feature Distributions:** Analyze the individual characteristics (central tendency, spread, shape) of each variable.
3.  **Detect Outliers & Anomalies:** Identify unusual data points that might represent extreme business events.
4.  **Uncover Correlations & Relationships:** Investigate how different features interact, both linearly and nonlinearly.
5.  **Engineer New Features:** Create derived variables to capture more complex business logic and potential drivers.
6.  **Answer Key Business Questions:** Provide data-driven answers to typical retail management inquiries.
7.  **Summarize Findings:** Consolidate insights for future modeling and strategic planning.

---

## ğŸ’¡ Methodology

The EDA process followed a structured approach, leveraging Python's powerful data science libraries:

1.  **Data Loading & Initial Inspection:**
    *   `df.head()`, `df.info()`, `df.describe()` to get a quick overview.
2.  **Data Quality Assessment:**
    *   Checked for missing values, duplicate rows, infinite values, and unexpected negative values.
3.  **Univariate Analysis:**
    *   Visualized distributions using **Histograms with KDEs**, **Box Plots**, and **Violin Plots**.
    *   Quantified `skewness` and `kurtosis` to understand distribution shapes.
4.  **Bivariate Analysis:**
    *   Explored relationships between pairs of features using **Scatter Plots**, **Pair Plots**, and **Hexbin Plots** for dense data.
5.  **Correlation Analysis:**
    *   Computed **Pearson**, **Spearman**, and **Kendall** correlation matrices.
    *   Visualized correlations with **Heatmaps** and a **Clustermap**.
    *   Identified the difference between Pearson and Spearman correlations to detect nonlinear monotonic relationships.
6.  **Outlier Detection:**
    *   Applied both **IQR (Interquartile Range)** and **Z-score** methods.
    *   Visualized outliers using combined box and strip plots.
7.  **Feature Engineering:**
    *   Created several meaningful derived features such as `effective_price`, `price_ratio`, `marketing_intensity`, `customer_experience`, and `stock_per_visitor`.
    *   Analyzed their distributions and correlations with original features.
8.  **Advanced Visualizations:**
    *   **Joint Plots** for detailed bivariate distributions.
    *   **Binned Analysis** to show average metrics across feature deciles (e.g., Avg Footfall by Price Decile).
    *   **Normalized KDE Overlays** for feature distribution comparison.
    *   **Radar/Spider Charts** to profile high vs. low performing product segments.
    *   **Cumulative Distribution Functions (CDFs)**.
9.  **Business Question Answering:**
    *   Addressed specific questions using aggregated data and insights from visualizations.

---

## ğŸ” Key Findings & Insights

-   **Data Pristine:** The dataset is exceptionally clean with no missing values or duplicates, making it immediately ready for analysis and modeling.
-   **Diverse Distributions:** Features exhibit a wide range of distributions, from symmetric to highly skewed, indicating the need for potential transformations in some modeling scenarios.
-   **Nonlinear Dynamics Confirmed:** The significant differences observed between Pearson and Spearman correlations highlight the prevalence of nonlinear, monotonic relationships, validating the dataset's design for complex interactions.
-   **Influential Factors Identified:**
    *   **Customer Sentiment & Return Rate:** A strong inverse correlation exists; higher sentiment leads to significantly lower return rates.
    *   **Ad Spend & Footfall:** Generally positive, but potentially nonlinear, relationship. Increased ad spend tends to drive more store traffic.
    *   **Promotion Intensity & Footfall:** Promotions are effective in attracting customers.
    *   **Competitive Pricing:** The store's pricing strategy relative to competitors has a notable impact on footfall and customer sentiment.
-   **Outliers are Present:** Outliers are detected across most features, likely representing legitimate extreme events (e.g., peak sales, heavy discounts, stockouts) rather than data errors.
-   **Enhanced Feature Set:** Engineered features like `effective_price`, `marketing_intensity`, and `customer_experience` provide richer, more interpretable insights than raw features alone, suggesting their value for predictive models.

---

## ğŸ–¼ï¸ Highlighted Visualizations

The notebook features a rich array of visualizations. Here are some key types:
<img width="1982" height="2224" alt="0cd97bf0-be0f-43b0-a45a-fb12a0e3cdc3" src="https://github.com/user-attachments/assets/d26e1184-9190-471d-b6bf-c43b5a44a982" />

-   **Correlation Heatmaps:** Visualizing Pearson, Spearman, and Kendall correlations to understand linear and monotonic relationships, plus a Clustermap for hierarchical grouping of features.
-   **Box & Violin Plots:** Providing detailed views of feature distributions and aiding in outlier detection.
-   <img width="2384" height="1022" alt="bf2c31cb-8ff3-401a-a21f-0f19511bc154" src="https://github.com/user-attachments/assets/483da2d6-50c1-4441-9dce-8144a86eaff2" />

-   **Joint & Hexbin Plots:** Effectively displaying dense bivariate relationships, such as `price` vs. `footfall` or `customer_sentiment` vs. `return_rate`.
-   <img width="2183" height="2426" alt="898bcf2b-76d5-41a3-aa2f-62395c2d4c8e" src="https://github.com/user-attachments/assets/b68c5a49-9bed-49ea-82eb-067ec996ef5e" />

-   **Radar Chart:** A compelling visual comparison of feature profiles for products with high vs. low footfall, revealing distinct characteristic differences.
-   **Binned Analysis:** Illustrating how average metrics (e.g., `footfall`, `return_rate`) change across deciles of other features (e.g., `price`, `discount`).
-   **Engineered Feature Distributions:** Histograms and KDEs for newly created features, showing their unique characteristics.
<img width="1584" height="684" alt="be2f6a34-ea00-47d4-94ee-88e725f069ef" src="https://github.com/user-attachments/assets/52593e32-59c1-4c85-948d-0aaf0b7f72e2" />

---

## â“ Key Business Questions Answered

The EDA successfully addressed several critical business questions:

-   **What is the average profile of a high-performing product (top 10% footfall)?**
-   **Does higher advertising spend lead to more store traffic?**
-   **Is there a relationship between customer sentiment and return rate?**
-   **How does pricing relative to competitors affect performance metrics?**
-   **What are the most important features for predicting footfall?**
-   **Are there any concerning multicollinearity issues among features?**
-   **Does weather affect store traffic and customer behavior?**
<img width="2184" height="1226" alt="c8bf2496-cccb-4d54-92b0-eaf73341a957" src="https://github.com/user-attachments/assets/85b76f62-85b0-4790-b882-d00456d9a1d9" />

---

## ğŸ’» Technical Stack

-   **Python:** 3.x
-   **Pandas:** For data manipulation and analysis.
-   **NumPy:** For numerical operations.
-   **Matplotlib:** For static, high-quality visualizations.
-   **Seaborn:** For enhanced statistical data visualization.
-   **SciPy:** For statistical functions (e.g., Z-scores, skewness/kurtosis calculations).
-   **Scikit-learn:** For data preprocessing utilities (`MinMaxScaler` used in some visualizations).

---

## âš™ï¸ How to Use/Run

To replicate this analysis:

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/[YourGitHubUsername]/[YourRepositoryName].git
    cd [YourRepositoryName]
    ```
2.  **Install dependencies:**
    It's recommended to use a virtual environment.
    ```bash
    pip install -r requirements.txt
    ```
    *(If you don't have a `requirements.txt` file, you can create one using `pip freeze > requirements.txt` after installing all libraries, or manually list them: `pandas numpy matplotlib seaborn scipy scikit-learn`)*
3.  **Download the dataset:**
    The dataset `retail_store_simulation_extended.csv` needs to be placed in the same directory as the notebook or adjusted path in the notebook.
    (You can find it on Kaggle: [Retail Store Product Sales Simulation Dataset](https://www.kaggle.com/datasets/thedevastator/retail-store-product-sales-simulation-dataset))
4.  **Open the Jupyter Notebook:**
    ```bash
    jupyter notebook retail_sales_eda.ipynb
    ```
5.  **Run all cells:** Execute the cells sequentially within the notebook to see the full EDA.

---

## ğŸ”® Future Work

This EDA serves as a strong foundation. Potential next steps include:

-   **Predictive Modeling:** Building regression models to predict `footfall` or other sales proxies. Given the nonlinearities, tree-based models (e.g., Random Forest, XGBoost) or neural networks would be highly suitable.
-   **Self-Supervised Learning:** Experimenting with autoencoders or masked-feature modeling for representation learning on this tabular dataset.
-   **Anomaly Detection:** Implementing more advanced anomaly detection algorithms to flag unusual product performance or market conditions.
-   **Causal Inference:** Exploring causal relationships between marketing efforts and sales outcomes using techniques like CausalImpact or structural equation modeling.

---

---

# ğŸ™ Thank You!

If you found this notebook helpful, please consider:
- â¬†ï¸ **Upvoting** this notebook
- ğŸ’¬ **Leaving a comment** with your thoughts or questions
- ğŸ”” **Following** me for more quality data science content

## ğŸŒ Connect With Me:
## ğŸ‘¤ About the Author

- **Author:** [Hammad_zahid]
- **Kaggle:** [kaggle.com/hammadansari7](https://www.kaggle.com/hammadansari7)
- **LinkedIn:** [linkedin.com/in/Hammad Zahid](https://www.linkedin.com/in/hammad-zahid-xyz/)
- **GitHub:** [github.com/Hamad-Ansari](https://github.com/Hamad-Ansari)
- **Twitter/X:** [@zahid_hamm57652](https://x.com/zahid_hamm57652)


---

*Happy analyzing! ğŸ“ŠğŸš€*
Feel free to connect, provide feedback, or ask any questions!

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---
